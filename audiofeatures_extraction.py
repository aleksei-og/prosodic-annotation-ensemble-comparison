import json
import os
import pandas as pd
import numpy as np
import librosa
from scipy.stats import skew, kurtosis, entropy
from scipy.signal import hilbert
import pywt
from tqdm import tqdm
import re

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
JSON_PATH = "project-1-at-2025-05-13-11-10-34463d27.json"
AUDIO_DIR = r"C:\Users\aleks\Desktop\jupyter without datasets\audiosets"
OUTPUT_CSV = "advanced_audio_features.csv"


def find_audio_file(audio_dir, filename_from_json):
    """–ù–∞—Ö–æ–¥–∏—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –Ω–∞–∑–≤–∞–Ω–∏—è"""
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ JSON (—á–∞—Å—Ç—å –ø–æ—Å–ª–µ –¥–µ—Ñ–∏—Å–∞)
    match = re.search(r'-(.+)\.mp3$', filename_from_json)
    if match:
        search_pattern = match.group(1)  # –ù–∞–ø—Ä–∏–º–µ—Ä: "In_a_restaurant"
    else:
        search_pattern = filename_from_json.replace('.mp3', '')

    # –ò—â–µ–º —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    for file in os.listdir(audio_dir):
        if file.endswith('.mp3') and search_pattern in file:
            return os.path.join(audio_dir, file)

    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é, –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±–æ–π —Ñ–∞–π–ª —Å –ø–æ—Ö–æ–∂–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º
    simple_name = search_pattern.replace('_', ' ').lower()
    for file in os.listdir(audio_dir):
        if file.endswith('.mp3'):
            file_simple = file.replace('.mp3', '').replace('_', ' ').lower()
            if simple_name in file_simple or file_simple in simple_name:
                return os.path.join(audio_dir, file)

    return None


def extract_advanced_audio_features(audio_path, start_time, end_time, sr=22050):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Å–µ–≥–º–µ–Ω—Ç–∞"""
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
        y, sr = librosa.load(audio_path, sr=sr)

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –≤ —Å—ç–º–ø–ª–∞—Ö
        start_sample = int(start_time * sr)
        end_sample = int(end_time * sr)

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞
        segment = y[start_sample:end_sample]

        if len(segment) < 512:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            return None

        features = {}

        # ===== –ë–ê–ó–û–í–´–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò –°–ò–ì–ù–ê–õ–ê =====
        features['amplitude_mean'] = np.mean(segment)
        features['amplitude_std'] = np.std(segment)
        features['amplitude_skew'] = skew(segment)
        features['amplitude_kurtosis'] = kurtosis(segment)
        features['amplitude_max'] = np.max(segment)
        features['amplitude_min'] = np.min(segment)
        features['amplitude_range'] = np.ptp(segment)

        # ===== –≠–ù–ï–†–ì–ï–¢–ò–ß–ï–°–ö–ò–ï –ü–†–ò–ó–ù–ê–ö–ò =====
        features['rms'] = np.mean(librosa.feature.rms(y=segment))
        features['energy'] = np.sum(segment ** 2)

        # ===== –í–†–ï–ú–ï–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò =====
        features['zero_crossing_rate'] = np.mean(librosa.feature.zero_crossing_rate(segment))
        features['zcr_std'] = np.std(librosa.feature.zero_crossing_rate(segment))

        # ===== –°–ü–ï–ö–¢–†–ê–õ–¨–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò =====
        stft = np.abs(librosa.stft(segment))

        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã
        spectral_centroids = librosa.feature.spectral_centroid(y=segment, sr=sr)
        features['spectral_centroid_mean'] = np.mean(spectral_centroids)
        features['spectral_centroid_std'] = np.std(spectral_centroids)

        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –ø–æ–ª–æ—Å—ã
        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=segment, sr=sr)
        features['spectral_bandwidth_mean'] = np.mean(spectral_bandwidth)

        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π —Å–ø–∞–¥
        spectral_rolloff = librosa.feature.spectral_rolloff(y=segment, sr=sr, roll_percent=0.85)
        features['spectral_rolloff_mean'] = np.mean(spectral_rolloff)

        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∞—è –ø–ª–æ—Å–∫–æ—Å—Ç—å
        spectral_flatness = librosa.feature.spectral_flatness(y=segment)
        features['spectral_flatness_mean'] = np.mean(spectral_flatness)

        # ===== MFCC –ü–†–ò–ó–ù–ê–ö–ò (13 –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤) =====
        mfccs = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=13)
        for i in range(13):
            features[f'mfcc_{i + 1}_mean'] = np.mean(mfccs[i])
            features[f'mfcc_{i + 1}_std'] = np.std(mfccs[i])

        # ===== –•–†–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ï –ü–†–ò–ó–ù–ê–ö–ò =====
        chroma_stft = librosa.feature.chroma_stft(y=segment, sr=sr)
        features['chroma_stft_mean'] = np.mean(chroma_stft)
        features['chroma_stft_std'] = np.std(chroma_stft)

        # ===== –ú–ï–õ-–°–ü–ï–ö–¢–†–û–ì–†–ê–ú–ú–ê =====
        mel_spec = librosa.feature.melspectrogram(y=segment, sr=sr, n_mels=128)
        features['mel_spectrogram_mean'] = np.mean(mel_spec)
        features['mel_spectrogram_std'] = np.std(mel_spec)

        # ===== –ü–†–ò–ó–ù–ê–ö–ò –ì–ê–†–ú–û–ù–ò–ö –ò –ü–ï–†–ö–£–°–°–ò–ò =====
        y_harmonic, y_percussive = librosa.effects.hpss(segment)
        features['harmonic_ratio'] = np.mean(y_harmonic ** 2) / (
                    np.mean(y_harmonic ** 2) + np.mean(y_percussive ** 2) + 1e-10)

        # ===== –¢–ï–ú–ü–û –ò –†–ò–¢–ú–ò–ß–ï–°–ö–ò–ï –ü–†–ò–ó–ù–ê–ö–ò =====
        tempo, beats = librosa.beat.beat_track(y=segment, sr=sr)
        features['tempo'] = tempo

        # ===== –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò =====
        features['duration'] = end_time - start_time
        features['sample_length'] = len(segment)
        features['non_silence_ratio'] = np.mean(np.abs(segment) > 0.01)

        return features

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {os.path.basename(audio_path)} [{start_time:.2f}-{end_time:.2f}s]: {str(e)}")
        return None


def process_json_data(json_path, audio_dir):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ JSON —Ñ–∞–π–ª–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""

    # –ó–∞–≥—Ä—É–∑–∫–∞ JSON
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    all_features = []
    found_files = {}

    print("–ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤...")
    for item in tqdm(data, desc="–ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤"):
        audio_filename_json = item['file_upload']
        audio_path = find_audio_file(audio_dir, audio_filename_json)

        if audio_path:
            found_files[audio_filename_json] = os.path.basename(audio_path)
        else:
            print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è: {audio_filename_json}")
            continue

    print(f"\n–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(found_files)} –∏–∑ {len(data)}")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    for item in tqdm(data, desc="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"):
        audio_filename_json = item['file_upload']

        if audio_filename_json not in found_files:
            continue

        audio_path = os.path.join(audio_dir, found_files[audio_filename_json])

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
        for annotation in item['annotations']:
            for result in annotation['result']:
                if result['type'] == 'labels':
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –∏ –º–µ—Ç–æ–∫
                    start_time = result['value']['start']
                    end_time = result['value']['end']
                    labels = result['value']['labels']

                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    features = extract_advanced_audio_features(audio_path, start_time, end_time)

                    if features is not None:
                        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                        features['audio_file_json'] = audio_filename_json
                        features['audio_file_actual'] = found_files[audio_filename_json]
                        features['start_time'] = start_time
                        features['end_time'] = end_time
                        features['labels'] = '|'.join(labels)
                        features['task_id'] = item['id']
                        features['original_length'] = result.get('original_length', 0)

                        all_features.append(features)

    return all_features


# –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å
print("–ù–∞—á–∞–ª–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∞—É–¥–∏–æ-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
print("–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∞—É–¥–∏–æ:", AUDIO_DIR)

# –ü—Ä–æ–≤–µ—Ä–∏–º –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã –µ—Å—Ç—å –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
print("\n–§–∞–π–ª—ã –≤ –∞—É–¥–∏–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
audio_files = [f for f in os.listdir(AUDIO_DIR) if f.endswith('.mp3')]
for file in audio_files:
    print(f"  - {file}")

print(f"\n–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(audio_files)} MP3 —Ñ–∞–π–ª–æ–≤")

# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
features_list = process_json_data(JSON_PATH, AUDIO_DIR)

if features_list:
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
    df = pd.DataFrame(features_list)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV
    df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8')

    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(df)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
    print(f"üìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫: {OUTPUT_CSV}")
    print(f"üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö: {df.shape}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–µ—Ç–∫–∞–º
    print(f"\nüè∑Ô∏è –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç–æ–∫:")
    label_counts = df['labels'].value_counts()
    for label, count in label_counts.items():
        print(f"  {label}: {count} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

    print(f"\nüìà –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df.columns)}")
    print("\n–ü–µ—Ä–≤—ã–µ 3 —Å–µ–≥–º–µ–Ω—Ç–∞:")
    print(df[['audio_file_actual', 'start_time', 'end_time', 'labels', 'duration']].head(3))

else:
    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏.")

print(f"\n–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df.columns) if features_list else 0}")